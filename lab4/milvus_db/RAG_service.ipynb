{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15aa7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "host = \"localhost\"\n",
    "port = \"19530\"\n",
    "\n",
    "milvus_client = MilvusClient(host=host, port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e046cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import FieldSchema, DataType, CollectionSchema\n",
    "\n",
    "VECTOR_LENGTH = 768  # check the dimensionality for Silver Retriever Base (v1.1) model\n",
    "\n",
    "id_field = FieldSchema(\n",
    "    name=\"id\", dtype=DataType.INT64, is_primary=True, description=\"Primary id\"\n",
    ")\n",
    "text = FieldSchema(\n",
    "    name=\"text\", dtype=DataType.VARCHAR, max_length=4096, description=\"Page text\"\n",
    ")\n",
    "embedding_text = FieldSchema(\n",
    "    \"embedding\",\n",
    "    dtype=DataType.FLOAT_VECTOR,\n",
    "    dim=VECTOR_LENGTH,\n",
    "    description=\"Embedded text\",\n",
    ")\n",
    "\n",
    "fields = [id_field, text, embedding_text]\n",
    "\n",
    "schema = CollectionSchema(\n",
    "    fields=fields,\n",
    "    auto_id=True,\n",
    "    enable_dynamic_field=True,\n",
    "    description=\"RAG Texts collection\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ac735",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"rag_texts_and_embeddings\"\n",
    "\n",
    "milvus_client.create_collection(collection_name=COLLECTION_NAME, schema=schema)\n",
    "\n",
    "index_params = milvus_client.prepare_index_params()\n",
    "\n",
    "index_params.add_index(\n",
    "    field_name=\"embedding\",\n",
    "    index_type=\"HNSW\",\n",
    "    metric_type=\"L2\",\n",
    "    params={\"M\": 4, \"efConstruction\": 64},  # lower values for speed\n",
    ")\n",
    "\n",
    "milvus_client.create_index(collection_name=COLLECTION_NAME, index_params=index_params)\n",
    "\n",
    "# checkout our collection\n",
    "print(milvus_client.list_collections())\n",
    "\n",
    "# describe our collection\n",
    "print(milvus_client.describe_collection(COLLECTION_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eaaf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data source and destination\n",
    "## the document origin destination from which document will be downloaded\n",
    "pdf_url = \"https://www.iab.org.pl/wp-content/uploads/2024/04/Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.pdf\"\n",
    "\n",
    "## local destination of the document\n",
    "file_name = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.pdf\"\n",
    "\n",
    "## local destination of the processed document\n",
    "file_json = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.json\"\n",
    "\n",
    "## local destination of the embedded pages of the document\n",
    "embeddings_json = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska-Embeddings.json\"\n",
    "\n",
    "## local destination of all above local required files\n",
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7319e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_pdf_data(pdf_url: str, file_name: str) -> None:\n",
    "    response = requests.get(pdf_url, stream=True)\n",
    "    with open(os.path.join(data_dir, file_name), \"wb\") as file:\n",
    "        for block in response.iter_content(chunk_size=1024):\n",
    "            if block:\n",
    "                file.write(block)\n",
    "\n",
    "\n",
    "download_pdf_data(pdf_url, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ed20c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "import fitz\n",
    "import json\n",
    "\n",
    "\n",
    "def extract_pdf_text(file_name, file_json):\n",
    "    document = fitz.open(os.path.join(data_dir, file_name))\n",
    "    pages = []\n",
    "\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        page_text = page.get_text()\n",
    "        pages.append({\"page_num\": page_num, \"text\": page_text})\n",
    "\n",
    "    with open(os.path.join(data_dir, file_json), \"w\") as file:\n",
    "        json.dump(pages, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "extract_pdf_text(file_name, file_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7e998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize data\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def generate_embeddings(file_json, embeddings_json, model):\n",
    "    pages = []\n",
    "    with open(os.path.join(data_dir, file_json), \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    for page in data:\n",
    "        pages.append(page[\"text\"])\n",
    "\n",
    "    embeddings = model.encode(pages)\n",
    "\n",
    "    embeddings_paginated = []\n",
    "    for page_num in range(len(embeddings)):\n",
    "        embeddings_paginated.append(\n",
    "            {\"page_num\": page_num, \"embedding\": embeddings[page_num].tolist()}\n",
    "        )\n",
    "\n",
    "    with open(os.path.join(data_dir, embeddings_json), \"w\") as file:\n",
    "        json.dump(embeddings_paginated, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "model_name = \"ipipan/silver-retriever-base-v1.1\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "generate_embeddings(file_json, embeddings_json, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313eb7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_embeddings(file_json, embeddings_json, client=milvus_client):\n",
    "    rows = []\n",
    "    with (\n",
    "        open(os.path.join(data_dir, file_json), \"r\") as t_f,\n",
    "        open(os.path.join(data_dir, embeddings_json), \"r\") as e_f,\n",
    "    ):\n",
    "        text_data, embedding_data = json.load(t_f), json.load(e_f)\n",
    "        text_data = list(map(lambda d: d[\"text\"], text_data))\n",
    "        embedding_data = list(map(lambda d: d[\"embedding\"], embedding_data))\n",
    "\n",
    "        for page, (text, embedding) in enumerate(zip(text_data, embedding_data)):\n",
    "            rows.append({\"text\": text, \"embedding\": embedding})\n",
    "\n",
    "    client.insert(collection_name=\"rag_texts_and_embeddings\", data=rows)\n",
    "\n",
    "\n",
    "insert_embeddings(file_json, embeddings_json)\n",
    "\n",
    "# load inserted data into memory\n",
    "milvus_client.load_collection(\"rag_texts_and_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a09554de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search\n",
    "def search(model, query, client=milvus_client):\n",
    "    embedded_query = model.encode(query).tolist()\n",
    "    result = client.search(\n",
    "        collection_name=\"rag_texts_and_embeddings\",\n",
    "        data=[embedded_query],\n",
    "        limit=1,\n",
    "        search_params={\"metric_type\": \"L2\"},\n",
    "        output_fields=[\"text\"],\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "result = search(model, query=\"Czym jest sztuczna inteligencja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "gemini_client = genai.Client(api_key=GEMINI_KEY)\n",
    "\n",
    "MODEL = \"gemini-2.0-flash\"\n",
    "\n",
    "\n",
    "def generate_response(prompt: str):\n",
    "    try:\n",
    "        # Send request to Gemini 2.0 Flash API and get the response\n",
    "        response = gemini_client.models.generate_content(\n",
    "            model=MODEL,\n",
    "            contents=prompt,\n",
    "        )\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0230f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(context: str, query: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "Jesteś inteligentnym asystentem, który odpowiada na pytania na podstawie dostarczonego kontekstu.\n",
    "Użyj wyłącznie informacji z kontekstu. Jeśli kontekst nie zawiera wystarczających danych, napisz, że brakuje informacji.\n",
    "\n",
    "Kontekst:\n",
    "{context}\n",
    "\n",
    "Pytanie:\n",
    "{query}\n",
    "\n",
    "Odpowiedź:\n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def rag(model, query: str) -> str:\n",
    "    # having all prepared functions, you can combine them together and try to build your own RAG!\n",
    "    search_result = search(model, query=query)\n",
    "\n",
    "    if not search_result or not search_result[0]:\n",
    "        return \"No relevant context found.\"\n",
    "\n",
    "    retrieved_texts = [hit[\"entity\"][\"text\"] for hit in search_result[0]]\n",
    "    context = \"\\n\\n\".join(retrieved_texts)\n",
    "\n",
    "    prompt = build_prompt(context=context, query=query)\n",
    "\n",
    "    answer = generate_response(prompt)\n",
    "\n",
    "    return answer or \"No response generated.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6d12e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sztuczna inteligencja (AI) to obszar informatyki, który skupia się na tworzeniu programów komputerowych zdolnych do wykonywania zadań, które wymagają ludzkiej inteligencji. Te zadania obejmują rozpoznawanie wzorców, rozumienie języka naturalnego, podejmowanie decyzji, uczenie się, planowanie i wiele innych. Głównym celem AI jest stworzenie systemów, które są zdolne do myślenia i podejmowania decyzji na sposób przypominający ludzki.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Czym jest sztuczna inteligencja?\"\n",
    "response = rag(model, query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-course-agh-lab-08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
